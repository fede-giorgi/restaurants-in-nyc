# Data

```{r}
# Load libraries
library(tidyverse) 
library(ggdensity)
library(lubridate)
library(dplyr)
library(purrr)

options(dplyr.width = Inf)
```

```{r}
# Load the dataset with specific column types
df <- read_csv("/Users/dian/Desktop/EDAV FInal Project/DOHMH_New_York_City_Restaurant_Inspection_Results.csv",
                 col_types = cols(
    .default = col_character(),      # Set default to character for safety
    CAMIS = col_double(),            # Unique ID
    ZIPCODE = col_character(),       # Important: Keep as character to prevent stripping leading zeros
    SCORE = col_double(),
    Latitude = col_double(),
    Longitude = col_double(),
    `Community Board` = col_double(),
    BIN = col_double(),
    BBL = col_double()
  ),
  show_col_types = FALSE
 ) |>
  # Clean up date columns immediately using lubridate
  mutate(`INSPECTION DATE` = mdy(`INSPECTION DATE`),
         `GRADE DATE` = mdy(`GRADE DATE`),
         `RECORD DATE` = mdy(`RECORD DATE`))
```

## Description

We have curated and merged 2 data sets for this project: 
1. "DOHMH New York City Restaurant Inspection Results" maintained by the NYC Department of Health and Mental Hygiene (DOHMH), serves as the official record of food safety compliance for restaurants and college cafeterias in New York City.
2. "Yelp Open Dataset" is maintained by Yelp and contains information about public ratings, reviews, and the current state of the restaurant (closed/open).

#### Dataset Overview
**1. DOHMH New York City Restaurant Inspection Results**
- Source: NYC Department of Health and Mental Hygiene (DOHMH) https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j/about_data.

- Scope: The dataset contains details on every sustained or initially cited violation from inspections conducted at active restaurants. 

- Update Frequency: The data on NYC Open Data is updated daily, meaning it reflects near real-time inspection activities, and we obtained the dataset on 10/30/2025.

**Key Variables:**
- `CAMIS` (Record ID): This is a unique 10-digit integer identifier for each restaurant for the DOHMH dataset.

- `SCORE`: The total deficiency points calculated at the end of an inspection. Points are added for every violation found, thus a score of 0 is perfect, while a higher score means worse condition.

- `GRADE`: The letter grade derived from the score.

    A: 0 to 13 points.
    B: 14 to 27 points.
    C: 28 or more points.
    Some are graded as 'P' (Pending) or 'N' (Not yet graded).

- `VIOLATIONS`: This field describes the specific health code infractions.

- `first_inspection`and `last_inspection`: Indicates the time period of inspections done on each restaurant.

**2. Yelp open data set**
- Source: Yelp Fusion API (Business Search Endpoint).
- Scope: This dataset provides business-level metadata and aggregate public sentiment metrics for New York City restaurants that correspond to the facilities listed in the DOHMH dataset.
- Methodology: Data was retrieved by querying the Yelp API using unique phone numbers extracted from the non-repeated DOHMH restaurant list.
- Integration: This dataset is designed to be joined with the DOHMH inspection records using the phone number as the common key.

**Key Variables:**
- query_phone (Join Key): The phone number used to query the API. This serves as the primary foreign key to link this sentiment data back to the specific restaurant records in the DOHMH dataset.

- yelp_rating: The aggregate star rating of the restaurant on a scale of 1 to 5. This serves as the primary quantitative proxy for "public sentiment" in the correlation analysis.

- review_count: The total number of reviews contributing to the rating. This variable helps weight the significance of the yelp_rating (e.g., distinguishing between a 5-star rating with 2 reviews vs. 200 reviews).

- is_closed: A boolean value (True/False) indicating if the business has been marked as permanently closed on Yelp. This is crucial for filtering out inactive businesses from the final analysis.

## Missing value analysis

#### **1. DOHMH New York City Restaurant Inspection Results**

```{r}
# Calculate percentage of missing values per column
missing_summary <- df |>
  summarise(across(everything(), ~ mean(is.na(.)) * 100)) |>
  pivot_longer(everything(), names_to = "column", values_to = "percent_missing") |>
  filter(percent_missing > 0) |> # Filter only columns with missing values
  arrange(desc(percent_missing))

# Bar chart
ggplot(missing_summary, aes(x = reorder(column, percent_missing), y = percent_missing)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Percentage of Missing Values by Column",
       x = "Variable", 
       y = "% Missing") +
  theme_minimal()
```

The bar chart highlights that GRADE and GRADE DATE are the variables with the highest missingness (approximately 50%). This is consistent with the inspection process, where many initial or administrative inspections generate a score but do not immediately result in a letter grade.

```{r}
# 1. Create patterns
missing_patterns <- df |>
  select(GRADE, `GRADE DATE`, SCORE, `VIOLATION CODE`, `ACTION`) |>
  mutate(across(everything(), is.na)) |>
  group_by(across(everything())) |>
  summarise(count = n(), .groups = "drop") |>
  arrange(desc(count)) |>
  ungroup() |>
  mutate(pattern_id = row_number()) |>
  pivot_longer(cols = -c(count, pattern_id), names_to = "variable", values_to = "is_missing")

# 2. Prepare data for plotting (Top 10 only)
top_patterns <- missing_patterns |>
  filter(pattern_id <= 10) |>
  # Create a descriptive Y-axis label including the count
  mutate(row_label = paste0("Pattern ", pattern_id, " (n = ", count, ")"))

# 3. Visualization
ggplot(top_patterns, aes(x = variable, y = fct_rev(fct_inorder(row_label)), fill = is_missing)) +
  geom_tile(color = "white") +
  
  # Manual colors: Orange for Missing, Grey for Present
  scale_fill_manual(values = c("TRUE" = "tomato", "FALSE" = "grey80"), 
                    labels = c("Present", "Missing")) +
  
  # English labels
  labs(title = "Common Missing Value Patterns",
       subtitle = "Which columns tend to be missing together? (Top 10 Patterns)",
       x = "Variable", 
       y = "Pattern Frequency", 
       fill = "Is Missing?") +
  
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Tilt x-axis text for readability
```

The heatmap reveals that missing data follows structural patterns rather than being random. While Pattern 1 represents complete inspections, Pattern 2 (almost as frequent) indicates cases where a SCORE exists but the GRADE is missing, likely representing "Grade Pending" or initial inspection stages. Pattern 3 highlights administrative violations where neither a score nor a grade is assigned.

## Restaurant-level aggregation

```{r}
# Helper functions to handle NAs safely
last_non_null <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA)
  tail(x, 1)
}

safe_mean <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA_real_)
  mean(x)
}

# --- DATA TRANSFORMATION ---
restaurants <- df |>
  # 1. TIME FILTER BEFORE GROUPING
  # Remove dummy dates (1900) and focus on relevant recent data (post-2015)
  filter(`INSPECTION DATE` >= ymd("2015-01-01")) |> 
  
  arrange(`INSPECTION DATE`) |>
  group_by(CAMIS) |>
  summarise(
    DBA      = first(na.omit(DBA)),    # Takes the first non-null name
    BORO     = first(na.omit(BORO)),
    BUILDING = first(BUILDING),
    STREET   = first(STREET),
    ZIPCODE  = first(ZIPCODE),
    PHONE    = first(PHONE),
    CUISINE_DESCRIPTION = first(`CUISINE DESCRIPTION`),
    
    # 2. ROBUST COORDINATES
    # If the first value is NA, the mean retrieves the location across inspections
    Latitude  = mean(Latitude, na.rm = TRUE), 
    Longitude = mean(Longitude, na.rm = TRUE),

    n_inspections    = n_distinct(`INSPECTION DATE`, na.rm = TRUE),
    first_inspection = min(`INSPECTION DATE`, na.rm = TRUE),
    last_inspection  = max(`INSPECTION DATE`, na.rm = TRUE),

    mean_score = safe_mean(SCORE),
    # Mean score provides a good summary of overall hygiene performance
    
    last_grade = last_non_null(GRADE),

    # Create a list of all unique violations ever received by the restaurant
    violations = list(unique(na.omit(`VIOLATION DESCRIPTION`))),
    .groups = "drop"
  )

cat("Final row count (Restaurants):", nrow(restaurants), "\n")

# View the resulting dataframe
restaurants
```

The original dataset is granular, containing multiple rows for every single inspection and violation. To perform a restaurant-level analysis—such as mapping cuisine locations or comparing hygiene standards across different culinary traditions—we aggregate the data to create a unique entry for each establishment, summarizing its history into single metrics like mean_score and average coordinates.

## Cuisine Grouping

```{r}
mapping <- c(
  # --- AMERICAN (Include ora Seafood, Jewish/Kosher e varianti regionali) ---
  "American"                       = "American",
  "New American"                   = "American",
  "Chicken"                        = "American",
  "Hamburgers"                     = "American",
  "Steakhouse"                     = "American",
  "Barbecue"                       = "American",
  "Hotdogs"                        = "American",
  "Hotdogs/Pretzels"               = "American",
  "Soul Food"                      = "American",
  "Continental"                    = "American",
  "Californian"                    = "American",
  "Southwestern"                   = "American",
  "Cajun"                          = "American",
  "Creole"                         = "American",
  "Creole/Cajun"                   = "American",
  "Hawaiian"                       = "American", # Poke è spesso fast casual
  
  # MERGE RICHIESTI:
  "Seafood"                        = "American", # Unito ad American
  "Jewish/Kosher"                  = "American", # Unito ad American (stile Deli)

  # --- CAFE, DELI, BAKERY & DESSERTS (Include Sandwiches e Salads) ---
  "Coffee/Tea"                     = "Cafe/Deli/Bakery",
  "Bakery Products/Desserts"       = "Cafe/Deli/Bakery",
  "Donuts"                         = "Cafe/Deli/Bakery",
  "Frozen Desserts"                = "Cafe/Deli/Bakery",
  "Pancakes/Waffles"               = "Cafe/Deli/Bakery",
  "Nuts/Confectionary"             = "Cafe/Deli/Bakery",
  "Fruits/Vegetables"              = "Cafe/Deli/Bakery",
  # Spostati qui come richiesto:
  "Sandwiches"                     = "Cafe/Deli/Bakery",
  "Sandwiches/Salads/Mixed Buffet" = "Cafe/Deli/Bakery",
  "Salads"                         = "Cafe/Deli/Bakery",
  "Soups/Salads/Sandwiches"        = "Cafe/Deli/Bakery",
  "Soups"                          = "Cafe/Deli/Bakery",
  "Juice, Smoothies, Fruit Salads" = "Cafe/Deli/Bakery",
  "Bagels/Pretzels"                = "Cafe/Deli/Bakery",
  "Bottled Beverages"              = "Cafe/Deli/Bakery",

  # --- ASIAN ---
  "Chinese"                        = "Asian",
  "Japanese"                       = "Asian",
  "Asian/Asian Fusion"             = "Asian",
  "Korean"                         = "Asian",
  "Thai"                           = "Asian",
  "Southeast Asian"                = "Asian",
  "Bangladeshi"                    = "Asian",
  "Filipino"                       = "Asian",
  "Pakistani"                      = "Asian",
  "Chinese/Japanese"               = "Asian",
  "Chinese/Cuban"                  = "Asian",
  "Indonesian"                     = "Asian",
  "Afghan"                         = "Asian",
  
  # --- LATIN AMERICAN ---
  "Mexican"                        = "Latin American",
  "Latin American"                 = "Latin American",
  "Caribbean"                      = "Latin American",
  "Tex-Mex"                        = "Latin American",
  "Peruvian"                       = "Latin American",
  "Brazilian"                      = "Latin American",
  "Chilean"                        = "Latin American",
  "Chimichurri"                    = "Latin American",
  
  # --- ITALIAN (Include Pizza) ---
  "Pizza"                          = "Italian",
  "Italian"                        = "Italian",
  
  # --- EUROPEAN (Spagnola, Est Europa, ecc.) ---
  "Spanish"                        = "European",
  "Irish"                          = "European",
  "Eastern European"               = "European",
  "Russian"                        = "European",
  "Polish"                         = "European",
  "German"                         = "European",
  "English"                        = "European",
  "Tapas"                          = "European",
  "Portuguese"                     = "European",
  "Czech"                          = "European",
  "Scandinavian"                   = "European",
  "Basque"                         = "European",
  "Armenian"                       = "European",

  # --- FRENCH ---
  "French"                         = "French",
  "New French"                     = "French",
  "Haute Cuisine"                  = "French",

  # --- MEDITERRANEAN / MIDDLE EASTERN ---
  "Mediterranean"                  = "Mediterranean/Middle Eastern",
  "Middle Eastern"                 = "Mediterranean/Middle Eastern",
  "Greek"                          = "Mediterranean/Middle Eastern",
  "Turkish"                        = "Mediterranean/Middle Eastern",
  "Falafel"                        = "Mediterranean/Middle Eastern",
  "Egyptian"                       = "Mediterranean/Middle Eastern",
  "Moroccan"                       = "Mediterranean/Middle Eastern",
  "Lebanese"                       = "Mediterranean/Middle Eastern",
  "Iranian"                        = "Mediterranean/Middle Eastern",

  # --- INDIAN ---
  "Indian"                         = "Indian",

  # --- OTHER ---
  "Other"                          = "Other",
  "Fusion"                         = "Other",
  "Australian"                     = "Other",
  "Polynesian"                     = "Other",
  "Not Listed/Not Applicable"      = "Other",
  "African"                        = "Other",
  "Ethiopian"                      = "Other"
)

# mapping
restaurants <- restaurants |>
  mutate(
    cuisine_group = mapping[CUISINE_DESCRIPTION],
    cuisine_group = ifelse(is.na(cuisine_group), "Other", cuisine_group)
  )

# check
restaurants |>
  count(cuisine_group, sort = TRUE)
``` 

#### **2. Yelp open data set**

The Yelp dataset contains no missing values or duplicates, as incomplete records were filtered out during the data extraction process. And we joined Yelp's dataset containing rating score,review counts, and open/close status with DOHMN dataset using unique phone numbers of the restaurants rather than address or name because it could be inconsistent or duplicated.

```{r}
# 1. Load the Yelp dataset
yelp_df <- read_csv("/Users/dian/restaurants-in-nyc/nyc_yelp_matches_FINAL.csv", 
                    col_types = cols(
                      query_phone = col_character(), 
                      .default = col_guess()
                    ))

cat("Missing values per column before joining:\n")
print(colSums(is.na(yelp_no_url)))

total_dupes <- sum(duplicated(yelp_df))
cat("\nTotal exact duplicate rows:", total_dupes, "\n")
```


```{r}
# 2. Prepare the Yelp data for joining
yelp_clean <- yelp_df |>
  mutate(
    phone_match_key = str_sub(as.character(query_phone), -10)
  ) |>
  distinct(phone_match_key, .keep_all = TRUE) |>
  select(-matches("url")) # <--- REMOVES any column containing "url"

# 3. Prepare the DOHMH (restaurants) data for joining
restaurants_clean <- restaurants |>
  mutate(
    phone_match_key = str_sub(str_remove_all(as.character(PHONE), "[^0-9]"), -10)
  )

# 4. Join the datasets
# Only join the restaurants with yelp data available
final_data <- restaurants_clean |>
  inner_join(yelp_clean, by = "phone_match_key")

# 5. Verify the result
cat("Original DOHMH count:", nrow(restaurants), "\n")
cat("Original Yelp count:", nrow(yelp_df), "\n")
cat("Final Joined count:", nrow(final_data), "\n")

# View the final data to confirm URL is gone
print(final_data)
```







