# Results

## Setup and Data loading

This section installs required packages and loads the dataset directly from the NYC Open Data API.

```{r}

# ==============================================================================
# SETUP & DEPENDENCIES 
# ==============================================================================
packages <- c(
  "tidyverse",
  "ggdensity",
  "lubridate",
  "dplyr",
  "purrr",
  "sf",
  "ggplot2"
  )

new_packages <- packages[!(packages %in% installed.packages()[, "Package"])]

if (length(new_packages) > 0) {
  install.packages(new_packages)
}

invisible(lapply(packages, library, character.only = TRUE))

# ==============================================================================
# VISUALIZATION THEME 
# ==============================================================================
theme_nyc <- function() {
  theme_minimal(base_family = "sans") +
    theme(
      # Typography: Bold "Newspaper Headline" style or Subway Signage
      plot.title = element_text(face = "bold", size = 18, color = "#121212", margin = margin(b = 10)),
      plot.subtitle = element_text(size = 12, color = "#444444", margin = margin(b = 15)),
      plot.caption = element_text(size = 9, color = "#666666", face = "italic"),
      
      # Axes: Strong and dark for structure
      axis.title = element_text(face = "bold", size = 11, color = "#121212"),
      axis.text = element_text(size = 10, color = "#222222"),
      
      # Grid: "The NYC Grid" (clean, thin major lines)
      panel.grid.major = element_line(color = "#e0e0e0", linewidth = 0.5),
      panel.grid.minor = element_blank(), # Remove minor grid lines to reduce visual noise
      
      # Legend and Layout
      legend.position = "top", # Position top for immediate readability
      legend.title = element_text(face = "bold", size = 10),
      legend.text = element_text(size = 10),
      
      # Facet Strips (Headers for multi-panel plots)
      strip.text = element_text(face = "bold", size = 11, hjust = 0),
      strip.background = element_rect(fill = "transparent", color = NA)
    )
}

# ==============================================================================
# DATA INGESTION (API)
# ==============================================================================

# Define the remote URL to ensure reproducibility
url_dati <- "https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD"

# Load the dataset directly from the web
df <- read_csv(url_dati,
    # Enforce specific column types to handle parsing issues upfront
    col_types = cols(
    .default = col_character(),
    CAMIS = col_double(),
    ZIPCODE = col_character(),
    SCORE = col_double(),
    Latitude = col_double(),
    Longitude = col_double(),
    `Community Board` = col_double(),
    BIN = col_double(),
    BBL = col_double()
  ),
  show_col_types = FALSE
 ) |>
  # Parse date columns from string (Month-Day-Year) to Date objects
  mutate(`INSPECTION DATE` = mdy(`INSPECTION DATE`),
         `GRADE DATE` = mdy(`GRADE DATE`),
         `RECORD DATE` = mdy(`RECORD DATE`))

# ==============================================================================
# DATA AGGREGATION AT RESTAURANT LEVEL 
# ==============================================================================

# Helper functions to handle NAs safely
last_non_null <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA)
  tail(x, 1)
}

safe_mean <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA_real_)
  mean(x)
}

restaurants <- df |>
  # Remove dummy dates (1900) and focus on relevant recent data (post-2015)
  filter(`INSPECTION DATE` >= ymd("2015-01-01")) |> 
  
  arrange(`INSPECTION DATE`) |>
  group_by(CAMIS) |>
  summarise(
    DBA      = first(na.omit(DBA)),
    BORO     = first(na.omit(BORO)),
    BUILDING = first(BUILDING),
    STREET   = first(STREET),
    ZIPCODE  = first(ZIPCODE),
    PHONE    = first(PHONE),
    CUISINE_DESCRIPTION = first(`CUISINE DESCRIPTION`),
    
    # If the first value is NA, the mean retrieves the location across inspections
    Latitude  = mean(Latitude, na.rm = TRUE), 
    Longitude = mean(Longitude, na.rm = TRUE),

    n_inspections    = n_distinct(`INSPECTION DATE`, na.rm = TRUE),
    first_inspection = min(`INSPECTION DATE`, na.rm = TRUE),
    last_inspection  = max(`INSPECTION DATE`, na.rm = TRUE),

    mean_score = safe_mean(SCORE),
    # Mean score provides a good summary of overall hygiene performance
    
    last_grade = last_non_null(GRADE),

    # Create a list of all unique violations ever received by the restaurant
    violations = list(unique(na.omit(`VIOLATION DESCRIPTION`))),
    .groups = "drop"
  )

# ==============================================================================
# CUISINE CATEGORIZATION MAPPING 
# ==============================================================================

mapping <- c(
  # --- AMERICAN (Include ora Seafood, Jewish/Kosher e varianti regionali) ---
  "American"                       = "American",
  "New American"                   = "American",
  "Chicken"                        = "American",
  "Hamburgers"                     = "American",
  "Steakhouse"                     = "American",
  "Barbecue"                       = "American",
  "Hotdogs"                        = "American",
  "Hotdogs/Pretzels"               = "American",
  "Soul Food"                      = "American",
  "Continental"                    = "American",
  "Californian"                    = "American",
  "Southwestern"                   = "American",
  "Cajun"                          = "American",
  "Creole"                         = "American",
  "Creole/Cajun"                   = "American",
  "Hawaiian"                       = "American", # Poke Ã¨ spesso fast casual
  "Seafood"                        = "American", # Unito ad American
  "Jewish/Kosher"                  = "American", # Unito ad American (stile Deli)

  # --- CAFE, DELI, BAKERY & DESSERTS (Include Sandwiches e Salads) ---
  "Coffee/Tea"                     = "Cafe/Deli/Bakery",
  "Bakery Products/Desserts"       = "Cafe/Deli/Bakery",
  "Donuts"                         = "Cafe/Deli/Bakery",
  "Frozen Desserts"                = "Cafe/Deli/Bakery",
  "Pancakes/Waffles"               = "Cafe/Deli/Bakery",
  "Nuts/Confectionary"             = "Cafe/Deli/Bakery",
  "Fruits/Vegetables"              = "Cafe/Deli/Bakery",
  # Spostati qui come richiesto:
  "Sandwiches"                     = "Cafe/Deli/Bakery",
  "Sandwiches/Salads/Mixed Buffet" = "Cafe/Deli/Bakery",
  "Salads"                         = "Cafe/Deli/Bakery",
  "Soups/Salads/Sandwiches"        = "Cafe/Deli/Bakery",
  "Soups"                          = "Cafe/Deli/Bakery",
  "Juice, Smoothies, Fruit Salads" = "Cafe/Deli/Bakery",
  "Bagels/Pretzels"                = "Cafe/Deli/Bakery",
  "Bottled Beverages"              = "Cafe/Deli/Bakery",

  # --- ASIAN ---
  "Chinese"                        = "Asian",
  "Japanese"                       = "Asian",
  "Asian/Asian Fusion"             = "Asian",
  "Korean"                         = "Asian",
  "Thai"                           = "Asian",
  "Southeast Asian"                = "Asian",
  "Bangladeshi"                    = "Asian",
  "Filipino"                       = "Asian",
  "Pakistani"                      = "Asian",
  "Chinese/Japanese"               = "Asian",
  "Chinese/Cuban"                  = "Asian",
  "Indonesian"                     = "Asian",
  "Afghan"                         = "Asian",
  
  # --- LATIN AMERICAN ---
  "Mexican"                        = "Latin American",
  "Latin American"                 = "Latin American",
  "Caribbean"                      = "Latin American",
  "Tex-Mex"                        = "Latin American",
  "Peruvian"                       = "Latin American",
  "Brazilian"                      = "Latin American",
  "Chilean"                        = "Latin American",
  "Chimichurri"                    = "Latin American",
  
  # --- ITALIAN (Include Pizza) ---
  "Pizza"                          = "Italian",
  "Italian"                        = "Italian",
  
  # --- EUROPEAN (Spagnola, Est Europa, ecc.) ---
  "Spanish"                        = "European",
  "Irish"                          = "European",
  "Eastern European"               = "European",
  "Russian"                        = "European",
  "Polish"                         = "European",
  "German"                         = "European",
  "English"                        = "European",
  "Tapas"                          = "European",
  "Portuguese"                     = "European",
  "Czech"                          = "European",
  "Scandinavian"                   = "European",
  "Basque"                         = "European",
  "Armenian"                       = "European",

  # --- FRENCH ---
  "French"                         = "French",
  "New French"                     = "French",
  "Haute Cuisine"                  = "French",

  # --- MEDITERRANEAN / MIDDLE EASTERN ---
  "Mediterranean"                  = "Mediterranean/Middle Eastern",
  "Middle Eastern"                 = "Mediterranean/Middle Eastern",
  "Greek"                          = "Mediterranean/Middle Eastern",
  "Turkish"                        = "Mediterranean/Middle Eastern",
  "Falafel"                        = "Mediterranean/Middle Eastern",
  "Egyptian"                       = "Mediterranean/Middle Eastern",
  "Moroccan"                       = "Mediterranean/Middle Eastern",
  "Lebanese"                       = "Mediterranean/Middle Eastern",
  "Iranian"                        = "Mediterranean/Middle Eastern",

  # --- INDIAN ---
  "Indian"                         = "Indian",

  # --- OTHER ---
  "Other"                          = "Other",
  "Fusion"                         = "Other",
  "Australian"                     = "Other",
  "Polynesian"                     = "Other",
  "Not Listed/Not Applicable"      = "Other",
  "African"                        = "Other",
  "Ethiopian"                      = "Other"
)

# mapping
restaurants <- restaurants |>
  mutate(
    cuisine_group = mapping[CUISINE_DESCRIPTION],
    cuisine_group = ifelse(is.na(cuisine_group), "Other", cuisine_group)
  )
```

## Geospatial Density Map


```{r}

# 1. Load the Shapefile
nyc_map <- read_sf("C:/Users/famig/OneDrive/Scuola/0 Columbia University/1 Fall 2025/STAT GR5702 - Exploratory Data Analysis & Visualization/EDAV/nybb_25d/nybb.shp") %>%
  st_transform(crs = 4326)

# 2. Data Cleaning for Geospatial Analysis
# We create a specific subset to avoid overwriting the main dataset accidentally
restaurants_geo <- restaurants %>%
  # IMPORTANT FIX: Remove rows without coordinates
  filter(!is.na(Longitude) & !is.na(Latitude)) %>%
  # Remove valid but incorrect coordinates (e.g., 0,0 points that land in the ocean)
  filter(Longitude < -70 & Latitude > 35)

# 3. Test Dot Map (Optional - run this first to check if points align with the map)
# This is lighter to render than the density map
ggplot() +
  geom_sf(data = nyc_map, fill = "grey95", color = "grey80") +
  geom_point(data = restaurants_geo, 
             aes(x = Longitude, y = Latitude), 
             size = 0.1, alpha = 0.1, color = "red") +
  facet_wrap(~ cuisine_group) +
  theme_void() +
  labs(title = "Dot Map Test: Restaurant Locations")

# 4. Final Density Heatmap
# Note: This creates a Kernel Density Estimation (KDE) over the map
ggplot() +
  # Base map layer
  geom_sf(data = nyc_map, fill = "grey95", color = "grey80", linewidth = 0.3) +
  
  # Density layer
  geom_hdr(data = restaurants_geo, 
           aes(x = Longitude, y = Latitude, fill = after_stat(probs)), 
           method = "kde", alpha = 0.6) +
  
  # Facet by cuisine to see specific clustering
  facet_wrap(~ cuisine_group, nrow = 3) + # Increased rows for better visibility
  
  # Styling
  scale_fill_viridis_d(option = "A", direction = -1, name = "Probability") +
  theme_void() +
  labs(title = "Restaurant Hotspots by Cuisine in NYC",
       subtitle = "Spatial density estimation of inspection locations",
       caption = "Source: NYC DOHMH & NYC Planning") +
  theme(strip.text = element_text(face = "bold"),
        legend.position = "bottom")
```

By overlaying restaurant coordinates on the NYC borough map using Kernel Density Estimation (KDE), we can visualize the spatial clustering of different culinary traditions. This visualization moves beyond simple counts to reveal distinct cultural enclaves (such as the three major "Chinatowns" in Manhattan, Queens, and Brooklyn) versus cuisines that are uniformly distributed across the city, such as American or Cafe/Deli establishments.


## Hygiene Score Analysis

```{r}
library(ggplot2)
library(dplyr)

# Filter data for the plot
score_analysis <- restaurants %>%
  # Remove extreme outliers (scores > 60 are rare) for better readability
  filter(mean_score < 60)

# Combined Boxplot + Violin Plot
ggplot(score_analysis, aes(x = reorder(cuisine_group, mean_score, FUN = median), y = mean_score)) +
  
  # Violin plot (bottom layer): Shows the shape/density of the distribution
  geom_violin(fill = "grey90", color = NA, alpha = 0.5) +
  
  # Boxplot (top layer): Shows median and quartiles
  geom_boxplot(width = 0.2, fill = "steelblue", outlier.size = 0.5, outlier.alpha = 0.3) +
  
  # Dashed red line at 13 (Threshold for Grade A)
  geom_hline(yintercept = 13, linetype = "dashed", color = "red", linewidth = 0.8) +
  annotate("text", x = 1, y = 14.5, label = "Grade A Limit (13)", 
           color = "red", size = 3, hjust = 0) +
  
  # Flip coordinates for readable labels
  coord_flip() + 
  labs(title = "Hygiene Scores by Cuisine Type",
       subtitle = "Lower score indicates better hygiene performance",
       x = "Cuisine Group",
       y = "Average Inspection Score") +
  theme_minimal() +
  theme(
    axis.text.y = element_text(face = "bold", size = 10),
    plot.title = element_text(face = "bold")
  )
```

We utilized a combined violin and boxplot to analyze the distribution of hygiene scores across cuisine groups. The red dashed line at a score of 13 marks the critical threshold for an "A" grade; the plot reveals that while the median scores for most cuisines fall within the "A" range, certain groups (such as Latin American and Asian cuisines) exhibit a wider distribution with a longer tail of higher scores, suggesting higher variance in compliance or inspection complexity.

