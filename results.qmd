# Results

```{r}
# Load libraries
library(tidyverse) 
library(ggdensity)
library(lubridate)
library(dplyr)
library(purrr)

options(dplyr.width = Inf)
```

## 1. Restaurant diversity and clusters in NYC (cosa si mangia a ny)

### 1.1 Geospatial Density Map

```{r}
# Load the dataset with specific column types
df <- read_csv("/Users/dian/Desktop/EDAV FInal Project/DOHMH_New_York_City_Restaurant_Inspection_Results.csv",
                 col_types = cols(
    .default = col_character(),      # Set default to character for safety
    CAMIS = col_double(),            # Unique ID
    ZIPCODE = col_character(),       # Important: Keep as character to prevent stripping leading zeros
    SCORE = col_double(),
    Latitude = col_double(),
    Longitude = col_double(),
    `Community Board` = col_double(),
    BIN = col_double(),
    BBL = col_double()
  ),
  show_col_types = FALSE
 ) |>
  # Clean up date columns immediately using lubridate
  mutate(`INSPECTION DATE` = mdy(`INSPECTION DATE`),
         `GRADE DATE` = mdy(`GRADE DATE`),
         `RECORD DATE` = mdy(`RECORD DATE`))
```

```{r}
# Helper functions to handle NAs safely
last_non_null <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA)
  tail(x, 1)
}

safe_mean <- function(x) {
  x <- x[!is.na(x)]
  if (length(x) == 0) return(NA_real_)
  mean(x)
}

# --- DATA TRANSFORMATION ---
restaurants <- df |>
  # 1. TIME FILTER BEFORE GROUPING
  # Remove dummy dates (1900) and focus on relevant recent data (post-2015)
  filter(`INSPECTION DATE` >= ymd("2015-01-01")) |> 
  
  arrange(`INSPECTION DATE`) |>
  group_by(CAMIS) |>
  summarise(
    DBA      = first(na.omit(DBA)),    # Takes the first non-null name
    BORO     = first(na.omit(BORO)),
    BUILDING = first(BUILDING),
    STREET   = first(STREET),
    ZIPCODE  = first(ZIPCODE),
    PHONE    = first(PHONE),
    CUISINE_DESCRIPTION = first(`CUISINE DESCRIPTION`),
    
    # 2. ROBUST COORDINATES
    # If the first value is NA, the mean retrieves the location across inspections
    Latitude  = mean(Latitude, na.rm = TRUE), 
    Longitude = mean(Longitude, na.rm = TRUE),

    n_inspections    = n_distinct(`INSPECTION DATE`, na.rm = TRUE),
    first_inspection = min(`INSPECTION DATE`, na.rm = TRUE),
    last_inspection  = max(`INSPECTION DATE`, na.rm = TRUE),

    mean_score = safe_mean(SCORE),
    # Mean score provides a good summary of overall hygiene performance
    
    last_grade = last_non_null(GRADE),

    # Create a list of all unique violations ever received by the restaurant
    violations = list(unique(na.omit(`VIOLATION DESCRIPTION`))),
    .groups = "drop"
  )
```


```{r}
mapping <- c(
  # --- AMERICAN (Include ora Seafood, Jewish/Kosher e varianti regionali) ---
  "American"                       = "American",
  "New American"                   = "American",
  "Chicken"                        = "American",
  "Hamburgers"                     = "American",
  "Steakhouse"                     = "American",
  "Barbecue"                       = "American",
  "Hotdogs"                        = "American",
  "Hotdogs/Pretzels"               = "American",
  "Soul Food"                      = "American",
  "Continental"                    = "American",
  "Californian"                    = "American",
  "Southwestern"                   = "American",
  "Cajun"                          = "American",
  "Creole"                         = "American",
  "Creole/Cajun"                   = "American",
  "Hawaiian"                       = "American", # Poke Ã¨ spesso fast casual
  
  # MERGE RICHIESTI:
  "Seafood"                        = "American", # Unito ad American
  "Jewish/Kosher"                  = "American", # Unito ad American (stile Deli)

  # --- CAFE, DELI, BAKERY & DESSERTS (Include Sandwiches e Salads) ---
  "Coffee/Tea"                     = "Cafe/Deli/Bakery",
  "Bakery Products/Desserts"       = "Cafe/Deli/Bakery",
  "Donuts"                         = "Cafe/Deli/Bakery",
  "Frozen Desserts"                = "Cafe/Deli/Bakery",
  "Pancakes/Waffles"               = "Cafe/Deli/Bakery",
  "Nuts/Confectionary"             = "Cafe/Deli/Bakery",
  "Fruits/Vegetables"              = "Cafe/Deli/Bakery",
  # Spostati qui come richiesto:
  "Sandwiches"                     = "Cafe/Deli/Bakery",
  "Sandwiches/Salads/Mixed Buffet" = "Cafe/Deli/Bakery",
  "Salads"                         = "Cafe/Deli/Bakery",
  "Soups/Salads/Sandwiches"        = "Cafe/Deli/Bakery",
  "Soups"                          = "Cafe/Deli/Bakery",
  "Juice, Smoothies, Fruit Salads" = "Cafe/Deli/Bakery",
  "Bagels/Pretzels"                = "Cafe/Deli/Bakery",
  "Bottled Beverages"              = "Cafe/Deli/Bakery",

  # --- ASIAN ---
  "Chinese"                        = "Asian",
  "Japanese"                       = "Asian",
  "Asian/Asian Fusion"             = "Asian",
  "Korean"                         = "Asian",
  "Thai"                           = "Asian",
  "Southeast Asian"                = "Asian",
  "Bangladeshi"                    = "Asian",
  "Filipino"                       = "Asian",
  "Pakistani"                      = "Asian",
  "Chinese/Japanese"               = "Asian",
  "Chinese/Cuban"                  = "Asian",
  "Indonesian"                     = "Asian",
  "Afghan"                         = "Asian",
  
  # --- LATIN AMERICAN ---
  "Mexican"                        = "Latin American",
  "Latin American"                 = "Latin American",
  "Caribbean"                      = "Latin American",
  "Tex-Mex"                        = "Latin American",
  "Peruvian"                       = "Latin American",
  "Brazilian"                      = "Latin American",
  "Chilean"                        = "Latin American",
  "Chimichurri"                    = "Latin American",
  
  # --- ITALIAN (Include Pizza) ---
  "Pizza"                          = "Italian",
  "Italian"                        = "Italian",
  
  # --- EUROPEAN (Spagnola, Est Europa, ecc.) ---
  "Spanish"                        = "European",
  "Irish"                          = "European",
  "Eastern European"               = "European",
  "Russian"                        = "European",
  "Polish"                         = "European",
  "German"                         = "European",
  "English"                        = "European",
  "Tapas"                          = "European",
  "Portuguese"                     = "European",
  "Czech"                          = "European",
  "Scandinavian"                   = "European",
  "Basque"                         = "European",
  "Armenian"                       = "European",

  # --- FRENCH ---
  "French"                         = "French",
  "New French"                     = "French",
  "Haute Cuisine"                  = "French",

  # --- MEDITERRANEAN / MIDDLE EASTERN ---
  "Mediterranean"                  = "Mediterranean/Middle Eastern",
  "Middle Eastern"                 = "Mediterranean/Middle Eastern",
  "Greek"                          = "Mediterranean/Middle Eastern",
  "Turkish"                        = "Mediterranean/Middle Eastern",
  "Falafel"                        = "Mediterranean/Middle Eastern",
  "Egyptian"                       = "Mediterranean/Middle Eastern",
  "Moroccan"                       = "Mediterranean/Middle Eastern",
  "Lebanese"                       = "Mediterranean/Middle Eastern",
  "Iranian"                        = "Mediterranean/Middle Eastern",

  # --- INDIAN ---
  "Indian"                         = "Indian",

  # --- OTHER ---
  "Other"                          = "Other",
  "Fusion"                         = "Other",
  "Australian"                     = "Other",
  "Polynesian"                     = "Other",
  "Not Listed/Not Applicable"      = "Other",
  "African"                        = "Other",
  "Ethiopian"                      = "Other"
)

# mapping
restaurants <- restaurants |>
  mutate(
    cuisine_group = mapping[CUISINE_DESCRIPTION],
    cuisine_group = ifelse(is.na(cuisine_group), "Other", cuisine_group)
  )
```


```{r}
library(sf)
library(ggplot2)
library(ggdensity)
library(dplyr)

# 1. Load the Shapefile
nyc_map <- read_sf("/Users/dian/restaurants-in-nyc/nybb_25d/nybb.shp") |>
  st_transform(crs = 4326)

# 2. Data Cleaning for Geospatial Analysis
# We create a specific subset to avoid overwriting the main dataset accidentally
restaurants_geo <- restaurants |>
  # IMPORTANT FIX: Remove rows without coordinates
  filter(!is.na(Longitude) & !is.na(Latitude)) |>
  # Remove valid but incorrect coordinates (e.g., 0,0 points that land in the ocean)
  filter(Longitude < -70 & Latitude > 35)

# 3. Test Dot Map (Optional - run this first to check if points align with the map)
# This is lighter to render than the density map
ggplot() +
  geom_sf(data = nyc_map, fill = "grey95", color = "grey80") +
  geom_point(data = restaurants_geo, 
             aes(x = Longitude, y = Latitude), 
             size = 0.1, alpha = 0.1, color = "red") +
  facet_wrap(~ cuisine_group) +
  theme_void() +
  labs(title = "Dot Map Test: Restaurant Locations")

# 4. Final Density Heatmap
# Note: This creates a Kernel Density Estimation (KDE) over the map
ggplot() +
  # Base map layer
  geom_sf(data = nyc_map, fill = "grey95", color = "grey80", linewidth = 0.3) +
  
  # Density layer
  geom_hdr(data = restaurants_geo, 
           aes(x = Longitude, y = Latitude, fill = after_stat(probs)), 
           method = "kde", alpha = 0.6) +
  
  # Facet by cuisine to see specific clustering
  facet_wrap(~ cuisine_group, nrow = 3) + # Increased rows for better visibility
  
  # Styling
  scale_fill_viridis_d(option = "A", direction = -1, name = "Probability") +
  theme_void() +
  labs(title = "Restaurant Hotspots by Cuisine in NYC",
       subtitle = "Spatial density estimation of inspection locations",
       caption = "Source: NYC DOHMH & NYC Planning") +
  theme(strip.text = element_text(face = "bold"),
        legend.position = "bottom")
```

By overlaying restaurant coordinates on the NYC borough map using Kernel Density Estimation (KDE), we can visualize the spatial clustering of different culinary traditions. This visualization moves beyond simple counts to reveal distinct cultural enclaves (such as the three major "Chinatowns" in Manhattan, Queens, and Brooklyn) versus cuisines that are uniformly distributed across the city, such as American or Cafe/Deli establishments.


## 2. Consumer preferences (cosa piace mangiare)


## 3. Inspection and hygene 

### 3.1 Hygiene Score Analysis based on Cuisine

```{r}
library(ggplot2)
library(dplyr)

# Filter data for the plot
score_analysis <- restaurants |>
  # Exclude "Other" to keep the comparison meaningful
  filter(cuisine_group != "Other") |>
  # Remove extreme outliers (scores > 60 are rare) for better readability
  filter(mean_score < 60)

# Combined Boxplot + Violin Plot
ggplot(score_analysis, aes(x = reorder(cuisine_group, -mean_score, FUN = median), y = mean_score)) +
  
  # Violin plot (bottom layer): Shows the shape/density of the distribution
  geom_violin(fill = "grey90", color = NA, alpha = 0.5) +
  
  # Boxplot (top layer): Shows median and quartiles
  geom_boxplot(width = 0.2, fill = "steelblue", outlier.size = 0.5, outlier.alpha = 0.3) +
  
  # Dashed red line at 13 (Threshold for Grade A)
  geom_hline(yintercept = 13, linetype = "dashed", color = "red", linewidth = 0.8) +
 annotate(
  "text",
  x = 0.7,
  y = 14,
  label = "Grade A Limit (13)",
  color = "red",
  size = 2.5,
  hjust = 0
) +
  
  # Flip coordinates for readable labels
  coord_flip() + 
  labs(title = "Hygiene Scores by Cuisine Type",
       subtitle = "Lower score indicates better hygiene performance",
       x = "Cuisine Group",
       y = "Average Inspection Score") +
  theme_minimal() +
  theme(
    axis.text.y = element_text(face = "bold", size = 10),
    plot.title = element_text(face = "bold"),

  )
```

We utilized a combined violin and boxplot to analyze the distribution of hygiene scores across cuisine groups. The red dashed line at a score of 13 marks the critical threshold for an "A" grade; the plot reveals that while the median scores for most cuisines fall within the "A" range, certain groups (such as Latin American and Asian cuisines) exhibit a wider distribution with a longer tail of higher scores, suggesting higher variance in compliance or inspection complexity.

### 3.2. Where are the less clean restaurants located?

```{r}
library(sf)
library(ggplot2)
library(dplyr)

# 1. Load and Transform Map (Exactly like the working code)
nyc_map <- read_sf("/Users/dian/restaurants-in-nyc/nybb_25d/nybb.shp") |>
  st_transform(crs = 4326)

# 2. Clean Data (Using the filter logic that worked for you)
# We use final_data, but filter out bad coordinates just like your example did
map_data <- final_data |>
  filter(!is.na(Longitude) & !is.na(Latitude)) |>
  # This filter removes "0,0" points that would distort the map
  filter(Longitude < -70 & Latitude > 35)

# 3. Plot: One Big Map (No Facets)
ggplot() +
  # Layer 1: The Base Map (Grey background)
  geom_sf(data = nyc_map, fill = "grey95", color = "grey80") +
  
  # Layer 2: The Dots (Using geom_point is safer/easier here)
  geom_point(data = map_data, 
             aes(x = Longitude, y = Latitude, color = last_grade), 
             size = 1, alpha = 0.7) +
  
  # Styling
  scale_color_manual(values = c("P" = "cornflowerblue", 
                                "N" = "purple",
                                "B" = "orange", 
                                "C" = "red"),
                     na.value = "grey80") +
  
  theme_void() +
  labs(title = "Restaurant Hygiene Grades in NYC",
       color = "Grade")
```



## 4. Correlation between inspection score and public sentiment: 


```{r}
library(ggalluvial)

# 1. Prepare data: Bin the Yelp ratings
alluvial_data <- final_data |>
  filter(!is.na(cuisine_group), !is.na(last_grade), !is.na(yelp_rating), !is.na(is_closed)) |>
  mutate(
    # Binning Yelp Ratings
    yelp_cat = case_when(
      yelp_rating >= 4.0 ~ "High (4-5)",
      yelp_rating >= 3.0 ~ "Med (3-3.9)",
      TRUE ~ "Low (<3)"
    ),
    # formatting status
    status = ifelse(is_closed, "Closed", "Open")
  ) |>
  # Count frequencies for the flow thickness
  group_by(cuisine_group, last_grade, yelp_cat, status) |>
  summarise(freq = n(), .groups = "drop")

# 2. Plot
ggplot(alluvial_data,
       aes(axis1 = cuisine_group, 
           axis2 = last_grade, 
           axis3 = yelp_cat,
           axis4 = status,
           y = freq)) +
  
  geom_alluvium(aes(fill = cuisine_group), width = 1/12) +
  geom_stratum(width = 1/12, fill = "grey90", color = "grey") +
  
  # Add text labels to the strata
  geom_text(stat = "stratum", aes(label = after_stat(stratum)), size = 3) +
  
  scale_x_discrete(limits = c("Cuisine", "Grade", "Yelp Rating", "Status")) +
  theme_minimal() +
  labs(title = "From Cuisine to Closure: The Flow of Restaurant Quality",
       y = "Number of Restaurants")
```

